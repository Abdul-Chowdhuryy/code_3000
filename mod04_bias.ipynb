{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4382d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2724"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa39c4",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_PATH = \"mod05_data/sample.csv\"\n",
    "df = pd.read_csv(DF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df7518",
   "metadata": {},
   "source": [
    "### Separate data by independent (X) and dependent (y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"income\", \"education_years\", \"zipcode_score\"]]\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eca751",
   "metadata": {},
   "source": [
    "### Split the data into a _training_ set (to build a model) and _test_ set (to validate a model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee208beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8b2bb",
   "metadata": {},
   "source": [
    "### Build a model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e35e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=seed\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf0e6b",
   "metadata": {},
   "source": [
    "### Use SHAP to explain the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36e22c",
   "metadata": {},
   "source": [
    "This will allow us to see which variables are most important to predicting the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c3bc9",
   "metadata": {},
   "source": [
    "### Import the `group` variable, which was **not** used in training this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf63702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_with_group = X_test.copy()\n",
    "X_test_with_group[\"group\"] = df.loc[X_test.index, \"group\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586369eb",
   "metadata": {},
   "source": [
    "### Look at the difference in SHAP values between the two groups across the variables used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f386018",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pd.DataFrame(shap_values.values, columns=X_test.columns)\n",
    "shap_df[\"group\"] = X_test_with_group[\"group\"].values\n",
    "\n",
    "shap_df.groupby(\"group\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de55d5",
   "metadata": {},
   "source": [
    "### Let's put `group` and `zipcode_score` in the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap(var):\n",
    "    # Extract SHAP values for the feature\n",
    "    shap_var = shap_values[:, var].values\n",
    "\n",
    "    # Plot the values of each group using different colors\n",
    "    plt.figure()\n",
    "    plt.scatter(\n",
    "        X_test[var],\n",
    "        shap_var,\n",
    "        c=X_test_with_group[\"group\"]\n",
    "    )\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(f\"SHAP value for var\")\n",
    "    plt.title(\"Proxy feature impact by group\")\n",
    "    plt.show()\n",
    "\n",
    "plot_shap(\"zipcode_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0093ea8",
   "metadata": {},
   "source": [
    "# Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263315fd",
   "metadata": {},
   "source": [
    "### What is a _SHAP_ (or Shapley) value? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526b1ca",
   "metadata": {},
   "source": [
    A SHAP (Shapley) value is a feature attribution method based on game theory that explains an individual prediction by calculating how much each feature contributed to the prediction relative to a baseline (average prediction). Each feature is treated as a “player” in a cooperative game, and the SHAP value represents its fair contribution to the final output, averaged over all possible combinations of features. This allows us to interpret both global feature importance and local prediction behavior.
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c18d6",
   "metadata": {},
   "source": [
    "### Suppose you built this model and then it is peer reviewed by another entity. If the reviewer asks whether you used the variable `group` in your model, what would your answer be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6935ad",
   "metadata": {},
   "source": [
    No, the variable group was not used in training or prediction. The model was trained only using the features income, education_years, and zipcode_score. The group variable was introduced afterward strictly for auditing purposes to evaluate potential bias in the model’s predictions.
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fff9a1",
   "metadata": {},
   "source": [
    "### If the reviewer asks whether the outcome of your model is correlated with `group`, what would your answer be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542fd88",
   "metadata": {},
   "source": [
    Although group was not directly used in the model, the model’s outcomes may still be correlated with group due to proxy variables such as zipcode_score, income, or education_years. If these features are correlated with the protected demographic group, the model can indirectly produce different prediction patterns across groups. The group-level comparison of SHAP values suggests whether one group systematically receives higher or lower contributions from certain features, which indicates potential disparate impact.
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2e3bd",
   "metadata": {},
   "source": [
    "### Construct a \"proxy feature impact by group\" plot for `income`. How is this plot different from the one for `zipcode_score`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac831097",
   "metadata": {},
   "outputs": [],
   "source": [
    plot_shap("income")
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9df879",
   "metadata": {},
   "source": [
    The income plot shows how the SHAP contribution of income changes as income increases and whether this effect differs between demographic groups. Compared to the zipcode_score plot, the income plot typically reflects a more direct economic relationship, where higher income increases predicted outcomes in a smoother pattern. In contrast, the zipcode_score plot often shows clearer separation between groups, suggesting it may act as a stronger proxy feature for demographic group membership. This indicates that location-based variables may introduce more bias than income alone.
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48271ca",
   "metadata": {},
   "source": [
    "### If, instead, you were the **reviewer**, what other questions might you ask the person who built this model? Give at least two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8c693b",
   "metadata": {},
   "source": [
    Do model performance metrics (such as error rates or prediction accuracy) differ significantly across demographic groups?

Are any input features highly correlated with the protected variable group, indicating proxy discrimination risk?

Was any fairness metric (e.g., disparate impact ratio, equal opportunity, calibration across groups) evaluated before deployment?

Were any bias mitigation techniques considered, such as feature removal, reweighting, or fairness-aware training methods?
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3000-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
